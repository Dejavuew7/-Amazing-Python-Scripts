{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MALARIA DETECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries for loading data and visualisation\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "\n",
    "# import for train-test-split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import for One Hot Encoding\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# importing libraries for Model\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization\n",
    "\n",
    "# importing libraries for evaluating the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data and Train-Test-Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Cells : (27558, 50, 50, 3) and labels : (27558,)\n"
     ]
    }
   ],
   "source": [
    "# loading the data of images and setting their labels\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "Parasitized = os.listdir(\"../input/cell-images-for-detecting-malaria/cell_images/Parasitized/\")\n",
    "\n",
    "for a in Parasitized:\n",
    "    \n",
    "    try:\n",
    "        image = cv2.imread(\"../input/cell-images-for-detecting-malaria/cell_images/Parasitized/\" + a)\n",
    "        image_from_array = Image.fromarray(image, 'RGB')\n",
    "        size_image = image_from_array.resize((50, 50))\n",
    "        data.append(np.array(size_image))\n",
    "        labels.append(0)\n",
    "    \n",
    "    except AttributeError:\n",
    "        print(\"\")\n",
    "\n",
    "Uninfected = os.listdir(\"../input/cell-images-for-detecting-malaria/cell_images/Uninfected/\")\n",
    "\n",
    "for b in Uninfected:\n",
    "\n",
    "    try:\n",
    "        image = cv2.imread(\"../input/cell-images-for-detecting-malaria/cell_images/Uninfected/\" + b)\n",
    "        image_from_array = Image.fromarray(image, 'RGB')\n",
    "        size_image = image_from_array.resize((50, 50))\n",
    "        data.append(np.array(size_image))\n",
    "        labels.append(1)\n",
    "    \n",
    "    except AttributeError:\n",
    "        print(\"\")\n",
    "\n",
    "# Creating single numpy array of all the images and labels\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print('Cells : {} and labels : {}'.format(data.shape , labels.shape))\n",
    "\n",
    "# lets shuffle the data and labels before splitting them into training and testing sets\n",
    "n = np.arange(data.shape[0])\n",
    "np.random.shuffle(n)\n",
    "data = data[n]\n",
    "labels = labels[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape (22046, 50, 50, 3) ,Test data shape (5512, 50, 50, 3) \n"
     ]
    }
   ],
   "source": [
    "### Splitting the dataset into the Training set and Test set\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(data, labels, test_size = 0.2, random_state = 0)\n",
    "\n",
    "print('Train data shape {} ,Test data shape {} '.format(X_train.shape, X_valid.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')  \n",
    "X_valid = X_valid.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding \n",
    "y_train = to_categorical(y_train)\n",
    "y_valid = to_categorical(y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Model\n",
    "classifier = Sequential()\n",
    "\n",
    "# CNN layers\n",
    "classifier.add(Conv2D(32, kernel_size=(3, 3), input_shape = (50, 50, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "classifier.add(BatchNormalization(axis = -1))\n",
    "classifier.add(Dropout(0.5))   # Dropout prevents overfitting\n",
    "\n",
    "classifier.add(Conv2D(32, kernel_size=(3, 3), input_shape = (50, 50, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "classifier.add(BatchNormalization(axis = -1))\n",
    "classifier.add(Dropout(0.5))\n",
    "\n",
    "classifier.add(Flatten())\n",
    "\n",
    "classifier.add(Dense(units=128, activation='relu'))\n",
    "classifier.add(BatchNormalization(axis = -1))\n",
    "classifier.add(Dropout(0.5))\n",
    "\n",
    "classifier.add(Dense(units=2, activation='softmax')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "184/184 [==============================] - 35s 188ms/step - loss: 0.8184 - accuracy: 0.6335 - val_loss: 1.1224 - val_accuracy: 0.5381\n",
      "Epoch 2/15\n",
      "184/184 [==============================] - 34s 186ms/step - loss: 0.5323 - accuracy: 0.7513 - val_loss: 3.7602 - val_accuracy: 0.5142\n",
      "Epoch 3/15\n",
      "184/184 [==============================] - 35s 190ms/step - loss: 0.3502 - accuracy: 0.8630 - val_loss: 2.3590 - val_accuracy: 0.6333\n",
      "Epoch 4/15\n",
      "184/184 [==============================] - 34s 183ms/step - loss: 0.2813 - accuracy: 0.8928 - val_loss: 0.5241 - val_accuracy: 0.8483\n",
      "Epoch 5/15\n",
      "184/184 [==============================] - 34s 186ms/step - loss: 0.2409 - accuracy: 0.9116 - val_loss: 0.7730 - val_accuracy: 0.8091\n",
      "Epoch 6/15\n",
      "184/184 [==============================] - 34s 186ms/step - loss: 0.2181 - accuracy: 0.9208 - val_loss: 0.4525 - val_accuracy: 0.8639\n",
      "Epoch 7/15\n",
      "184/184 [==============================] - 34s 187ms/step - loss: 0.2018 - accuracy: 0.9280 - val_loss: 0.2444 - val_accuracy: 0.9176\n",
      "Epoch 8/15\n",
      "184/184 [==============================] - 34s 186ms/step - loss: 0.1875 - accuracy: 0.9325 - val_loss: 0.2131 - val_accuracy: 0.9332\n",
      "Epoch 9/15\n",
      "184/184 [==============================] - 34s 182ms/step - loss: 0.1809 - accuracy: 0.9363 - val_loss: 0.2225 - val_accuracy: 0.9278\n",
      "Epoch 10/15\n",
      "184/184 [==============================] - 34s 184ms/step - loss: 0.1742 - accuracy: 0.9381 - val_loss: 0.3947 - val_accuracy: 0.8830\n",
      "Epoch 11/15\n",
      "184/184 [==============================] - 34s 182ms/step - loss: 0.1653 - accuracy: 0.9433 - val_loss: 0.1856 - val_accuracy: 0.9341\n",
      "Epoch 12/15\n",
      "184/184 [==============================] - 34s 184ms/step - loss: 0.1569 - accuracy: 0.9459 - val_loss: 0.3146 - val_accuracy: 0.9006\n",
      "Epoch 13/15\n",
      "184/184 [==============================] - 35s 191ms/step - loss: 0.1565 - accuracy: 0.9466 - val_loss: 1.4489 - val_accuracy: 0.6170\n",
      "Epoch 14/15\n",
      "184/184 [==============================] - 36s 195ms/step - loss: 0.1493 - accuracy: 0.9475 - val_loss: 0.2734 - val_accuracy: 0.9178\n",
      "Epoch 15/15\n",
      "184/184 [==============================] - 36s 198ms/step - loss: 0.1403 - accuracy: 0.9518 - val_loss: 0.2161 - val_accuracy: 0.9318\n"
     ]
    }
   ],
   "source": [
    "history = classifier.fit(X_train, y_train, batch_size=120, epochs=15, verbose=1, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173/173 [==============================] - 3s 16ms/step - loss: 0.2161 - accuracy: 0.9318\n",
      "Test_Accuracy: 93.18%\n"
     ]
    }
   ],
   "source": [
    "print(\"Test_Accuracy: {:.2f}%\".format(classifier.evaluate(X_valid, y_valid)[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Summary of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 22, 22, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 11, 11, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 11, 11, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 11, 11, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3872)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               495744    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 506,914\n",
      "Trainable params: 506,530\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction, Evaluation and Testing of the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lets do our first prediction using predict and predict X_valid and store in y_pred variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert back to categorical values \n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_valid = np.argmax(y_valid, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.9317851959361393\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy Score: ', accuracy_score(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Evaluation of the CNN model by Plotting Confusion Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f2134173b10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWcAAAD4CAYAAAAw/yevAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAaFklEQVR4nO3deZhU1bX38e/qAVQmmWmGKCpyxSEYAsE4IiCoKOJ0W40YxTTxahxichGcokjUOCQaIwlOQKIiDlwcQEXEKVGQIC+T8oqK0tA0iswg0FXr/lFHbiHd1dXQ0LuPv4/Pfrpqn2mf5ylXLdbZ55S5OyIiEpacmh6AiIjsSMFZRCRACs4iIgFScBYRCZCCs4hIgPJ29wE2TXtY00FkB10LH67pIUiA5pW+Z7u6j61ffZp1zMlvdsAuH293UeYsIhKg3Z45i4jsUclETY+gWig4i0i8JMpqegTVQsFZRGLFPVnTQ6gWCs4iEi9JBWcRkfAocxYRCZAuCIqIBEiZs4hIeFyzNUREAqQLgiIiAVJZQ0QkQLogKCISIGXOIiIB0gVBEZEAxeSCoB4ZKiKx4p7IumViZu3MbJqZfWhm883sqqj/d2a21MxmR+2UtG2GmtkiM1toZn3S+ruY2dxo2f1mVulzpJU5i0i8VF/NuQy41t1nmVkD4N9mNiVa9kd3vzt9ZTPrBBQChwKtgdfM7GBPfQuMBIqA94BJQF9gcqaDK3MWkXhJJrNvGbh7ibvPil6vAz4E2mTYpD8wzt03u/tnwCKgm5kVAA3d/V13d2AscEZlp6HgLCLx4smsm5kVmdnMtFZU3i7NbH/gSGB61HWFmc0xs0fNrHHU1wZYkrZZcdTXJnr93f6MVNYQkXhJbM16VXcfBYzKtI6Z1QeeBa5297VmNhIYDnj09x7gEqC8OrJn6M9IwVlE4qUaZ2uYWT6pwPy4uz8H4O6lacsfAl6M3hYD7dI2bwssi/rbltOfkcoaIhIvVShrZBLNqHgE+NDd703rL0hbbQAwL3r9PFBoZnXNrD3QAZjh7iXAOjPrHu1zIDCxstNQ5iwi8VJ9mfPRwIXAXDObHfUNA84zs86kShOLgcEA7j7fzMYDC0jN9Ljc/2++3mXAaGBvUrM0Ms7UAAVnEYmbagrO7v4O5deLJ2XYZgQwopz+mcBhVTm+grOIxIpX4YJgyBScRSRe9OAjEZEAxeTZGgrOIhIvypxFRAKkzFlEJEDKnEVEAlSmh+2LiIRHmbOISIBUcxYRCZAyZxGRAClzFhEJkDJnEZEAabaGiEiAvNIfGakVFJxFJF5UcxYRCZCCs4hIgHRBUEQkQIlE5evUAgrOIhIvKmuIiARIwVlEJECqOYuIhMeTmucsIhIelTVERAKk2RoiIgFS5iwiEiAF53hb/vVabhg9iZVrN2BmnHXMD7mgZ5dy1523uISBdz7OnZeeRu8uHXfpuFu2lnHD6El8+EUpjertzZ2XnkabZo1YtnIN1/5tIolkkrJEkvN6/Ihzjuu8S8eSqqtTtw5jJo6kTp065ObmMuXF1/nLXQ+Xu+5hnQ/h8UkP85uiG5jy4rRdOm5+nXxuf+BmOh3RkdWr1vKbohtYtqSEjod24MY//Df169cjmUwy6k+jeXnia7t0rFovJg8+yqnpAYQqNzeHa8/uwYTfDeLvQ37GU29+wCfLvtphvUQyyX0T3uKoTvtXaf9Lv1rDoHvG7dA/4Z9zabjPXrww/Bf8rGcX7pvwJgDNG9VnzG/PZ/wNP+cfQ37Goy9PZ8Xq9Tt1brLztmzewiVnXsFZJ17I2T0v5OgTj+KILofusF5OTg7X3Hg5/5w2vUr7b92ugMeee3CH/jPPP521q9dySvdz+PvfnuTXN14OwDebvmHYFbdyxvHnM7jwaoYMv5oGDevv3MnFRTKZfQtYpZmzmf0H0B9oAziwDHje3T/czWOrUc0b1ad5o9SHvN5edTigVVNWrF7Pga2bbbfek9Nm0fPIDsxfvHy7/pemz+eJ12exNZHg8PYFDDuvN7k5lX8XvjFnEb/s91MAev2oI3eMm4q7k5+Xu22dLWUJPCbZQW20aeMmAPLy88jLyys3UTv/0nOY8uI0Duvcabv+fmf15YJfnEN+fj5zZs3ntiF3kcwiSJzY91gevDuVob/6wjSG/f43AHz+6ZJt63xZ+hVff7WKxk0bs27t9/iLOyZT6TJGCzMbAowDDJgBvB+9ftLMrtv9wwvD0q/W8NGSUg5vX7Bdf+mqdUyb/fEO5YVPS1byysyFjP7vVKabYzlMmrEgq2OtWL2eVo0bApCXm0P9veuwekMqGCz/ei3nDH+MvkP/ys/7dKPFvt/zDKmG5OTk8MzUsbw1fzLvvjmDubPmb7e8Ravm9Dz5eMaPmbBd/wEd9qfvGb24sF8RZ/ccSDKRpN9ZfbI6ZouC5ixfWgpAIpFg/br17Nuk0XbrHHZkJ/Lz81myuHgXzi4GEonsW8Aqy5wHAYe6+9b0TjO7F5gP3FHeRmZWBBQB/PnXFzKo33HVMNSasfGbLfxm1ER+e+6J1N+77nbL7nr6da4acPwOGfGMjz7nwy+Wc8Htfwdg89YymjTYB4BrRk5g6co1lJUlKVm1lnNvGw3A+Sd24YyfHl5uRmwYAK2aNOTpGy9mxer1XDNyAr1/1JGmDetV9ylLJZLJJGf3HEiDhvW5b/SdHPQfB7Doo0+3LR8y/Gr+eNtfdsiIf3Lsj+l0REfGvfIYAHX3qsvXX60C4L7H7qDND1qTn59PQduWPDN1LAD/eOgp/mfcS9s+A+nSPyvNWjTl9gdu5vorb/3e/6vKAy9XZKuy4JwEWgOff6e/IFpWLncfBYwC2DTt4Vr7SdmaSHDtqImc0u0Qeh558A7LF3xeypCHXwBg9YZNvDP/M3Jzc3DgtO6HceWAHb+U/njZACCVjd80ZjKPXFu43fKWjRuwfNVaWjZuQFkiyfpNW2hUb6/t1mmxb30ObN2MWR8X7/IFSNl569au5/1/zuKYHt23C86Hdj6Eu/56GwCNmzbi2F5HkUgkMDOeHz+JP40YucO+rro49Q/R1u0KGHHfjVx85n9tt7y0ZAWt2rSktORLcnNzqd+gPmtWrQWgXv19ePDxe/nzHX9jzr/n77Dv751qKmuYWTtgLNCKVLwb5e73mVkT4Clgf2AxcK67r4q2GUoqqU0AV7r7K1F/F2A0sDcwCbjKK/kWrawIejUw1cwmm9moqL0MTAWuqvrp1h7uzi1jX6Z9q6Zc2KtruetMGlHE5N8PZvLvB9PryIMZVtiLEzt3oFvHHzBl1kK+XrsBgDUbNrFs5Zqsjnv8EQfywrup/8Fem7WQrh1/gJlRumod32xJ/QNm7YZvmP3JUvZv1aQazlSqonHTfbddcKu7V126H9eVzxZtn7v07XomfboOoE/XAbz6wjRuG3IXr09+i/fefp/e/U6kSbPGADTctyEFbVtlddxpr7xN/3NPAeCk03ow/Z2ZQKrufd/oO3n+6Um8+sLr1XWatZsns2+ZlQHXuvshQHfgcjPrBFwHTHX3DqRi4XUA0bJC4FCgL/CgmX17sWgkqWpCh6j1rezgGTNnd3/ZzA4GupG6IGhAMfC+u4ddsNlFsz9ZyovTF9ChTbNtpYdf9T+O5VG2kmka24Gtm3FF/2P55f1P4+7k5eYytLAXrZs2qnCbbw04+giuf+wlTrvxIRrusxd3XnoakKpj3/vsNAzDcQb27kqHNs13/USlSpq3bMaI+28kNzcXyzFemTiVN6f8k3MHpv5FNH7shAq3/fT/L+bPd/yNUU/dR05ODlu3ljFi6F2UFC+vcJtvPffEC9z+wM1Meu9p1qxey28H3whA39N70aX7kezbuBFn/OepAFx/5XAWzv+4Gs62lqqmzNndS4CS6PU6M/uQVBzsD5wQrTYGeAMYEvWPc/fNwGdmtgjoZmaLgYbu/i6AmY0FzgAmZzq+7e76VG0ua8ju07Ww/LnB8v02r/S9HYvrVbThpsKsY0794U8NJro+FhkVlWW3Y2b7A28BhwFfuPu+actWuXtjM3sAeM/d/xH1P0IqAC8G7nD3XlH/scAQd++XaWy6CUVE4qUKjwxNvz5WETOrDzwLXO3ua80q/P4ob4Fn6M9IwVlE4qUa5zmbWT6pwPy4uz8XdZeaWYG7l5hZAbAi6i8G2qVt3pbUfSHF0evv9mekOwRFJFY8mcy6ZWKpFPkR4EN3vzdt0fPARdHri4CJaf2FZlbXzNqTuvA3I6pdrzOz7tE+B6ZtUyFlziISL9WXOR8NXAjMNbPZUd8wUvd3jDezQcAXwDkA7j7fzMYDC0jN9Lg8beLEZfzfVLrJVHIxEBScRSRuqm+2xjuUXy8G6FnBNiOAEeX0zyR1MTFrCs4iEi+B35adLQVnEYkV/YagiEiIFJxFRAL0PXnwkYhI7aLMWUQkQArOIiLh8YTKGiIi4VHmLCISHk2lExEJkYKziEiA4lFyVnAWkXjxsnhEZwVnEYmXeMRmBWcRiRddEBQRCZEyZxGR8ChzFhEJkTJnEZHweFlNj6B6KDiLSKy4MmcRkQApOIuIhEeZs4hIgBScRUQC5Amr6SFUCwVnEYkVZc4iIgHypDJnEZHgKHMWEQmQuzJnEZHgKHMWEQlQUrM1RETCowuCIiIBiktwzqnpAYiIVCf37FtlzOxRM1thZvPS+n5nZkvNbHbUTklbNtTMFpnZQjPrk9bfxczmRsvuN7NKv0EUnEUkVjxpWbcsjAb6ltP/R3fvHLVJAGbWCSgEDo22edDMcqP1RwJFQIeolbfP7Sg4i0isuFvWrfJ9+VvA11keuj8wzt03u/tnwCKgm5kVAA3d/V13d2AscEZlO1NwFpFYSSQs67YLrjCzOVHZo3HU1wZYkrZOcdTXJnr93f6MFJxFJFaqkjmbWZGZzUxrRVkcYiRwINAZKAHuifrLi/aeoT8jzdYQkVipymwNdx8FjKrS/t1Lv31tZg8BL0Zvi4F2aau2BZZF/W3L6c9ImbOIxEp1ztYoT1RD/tYA4NuZHM8DhWZW18zak7rwN8PdS4B1ZtY9mqUxEJhY2XGUOYtIrFTnPGczexI4AWhmZsXAzcAJZtaZVGliMTAYwN3nm9l4YAFQBlzu7oloV5eRmvmxNzA5ahkpOItIrCSS1VcQcPfzyul+JMP6I4AR5fTPBA6ryrEVnEUkVna2XBEaBWcRiZWkHhkqIhIePc9ZRCRAKmtkqUGfm3f3IaQW2rTs7ZoegsSUyhoiIgGqztkaNUnBWURiJSZVDQVnEYkXlTVERAKk2RoiIgGKyY9vKziLSLx4uU/orH0UnEUkVspU1hARCY8yZxGRAKnmLCISIGXOIiIBUuYsIhKghDJnEZHwVOOvVNUoBWcRiZWkMmcRkfDowUciIgHSBUERkQAlTWUNEZHgJGp6ANVEwVlEYkWzNUREAqTZGiIiAdJsDRGRAKmsISISIE2lExEJUEKZs4hIeJQ5i4gESMFZRCRAMfkJQXJqegAiItUpWYVWGTN71MxWmNm8tL4mZjbFzD6O/jZOWzbUzBaZ2UIz65PW38XM5kbL7jer/B5zBWcRiZVEFVoWRgN9v9N3HTDV3TsAU6P3mFknoBA4NNrmQTPLjbYZCRQBHaL23X3uQMFZRGIladm3yrj7W8DX3+nuD4yJXo8BzkjrH+fum939M2AR0M3MCoCG7v6uuzswNm2bCik4i0isVKWsYWZFZjYzrRVlcYiW7l4CEP1tEfW3AZakrVcc9bWJXn+3PyNdEBSRWKnKbA13HwWMqqZDl5eLe4b+jJQ5i0iseBXaTiqNShVEf1dE/cVAu7T12gLLov625fRnpOAsIrFSnTXnCjwPXBS9vgiYmNZfaGZ1zaw9qQt/M6LSxzoz6x7N0hiYtk2FVNYQkVipzoftm9mTwAlAMzMrBm4G7gDGm9kg4AvgHAB3n29m44EFQBlwubt/O5zLSM382BuYHLWMFJxFJFaS1fjQUHc/r4JFPStYfwQwopz+mcBhVTm2grOIxIpu3xYRCZAeti8iEiBlziIiASqzeOTOCs4iEivxCM0KziISMypriIgEqDqn0tUkBWcRiZV4hGYFZxGJGZU1REQClIhJ7qzgLCKxosxZRCRArsxZRCQ8ypwlo7p16/LG689Sp25d8vJyee65l7jl1nu2Lf/1NYP5w5030bLgMFauXFWDI5WqKCn9kmHD7+arr1eRY8bZ/U/mwnO3/zm4Rx9/hpdenQZAIpHg08+X8PZL42jUsMFOH3fLli0MHX4PCxZ+zL6NGnL3rUNpU9CSZctLuXrYbSQSScrKyjj/7NP5zwGn7tI51naaSicZbd68mV4nncuGDRvJy8vjrTcm8PLL05g+YxZt27amV8/j+Pzz4sp3JEHJy83lt7/6BZ06HsSGDRs5d9CV/LTrkRzYfr9t61xywdlccsHZALzxznuMfep/sg7MS0tKuX7EPYx+4A/b9T/34qs0bFCfyeMfZdJrb3Dvg49yz/ChNG/ahH/89R7q1KnDxo2bOOPCX9LjmO60aN60+k66lolHaNYvoexWGzZsBCA/P4+8/HxSP7wL99z9O64bNmLbe6k9mjdrQqeOBwFQr94+HLBfO0q/XFnh+pNee5NTeh+/7f0Lr7xO4aVXcdZFl3PLH+4nkcju0fCvv/0u/U/pBcBJJxzL9H/Pxt3Jz8+nTp06AGzZupWkPlOU4Vm3kCk470Y5OTnMfP9VSpbOYerUt5jx/gf069ebpUtLmDNnQU0PT3bR0pJSPvz4E444tGO5yzd98w3vvDeT3iccA8Ani7/g5alv8ve/3sOzY/5CTk4OL0blj8qs+HIlrVo0AyAvL5f69fZh9Zq1QKrUMmDgZfQaMJBBF5zzvc6aIXVBMNv/QrbTZQ0zu9jdH6tgWRFQBGC5jcjJqbezh6nVkskkP+56Eo0aNeTZpx/h8MMPYdh1V9L3lPNremiyizZu3MQ119/GkCsHU79e+Z/vN96ZzpFHdNpW0pg+czYLPlpE4aCrgFTpq0njfQG4cuitLF1WytayrZSUfslZF10OwM/O7c+AU08q919ZqZ+jg4KWzZkwdiQrvlzJlUNvpXePY2jWpHG1n3NtoQuCcAtQbnBO/7nxvDptwv562gPWrFnLm2/9i9NP68P++/+AWTOnANC2bQHvT3+Fo44+ldLSL2t4lJKtrWVlXH39bZx6Ug96n3B0hetNnvomp/Q6Ydt7d+f0k3txzWUX77Du/bffBFRcc27ZohnLV3xFqxbNKStLsH7Dxh3q2C2aN+Wg9vsx6//N46Qex+7CGdZuoWfE2cpY1jCzORW0uUDLPTTGWqlZsyY0atQQgL322oueJx7L7NnzaN32hxx0cHcOOrg7xcUldP1JHwXmWsTduen2P3HAfu24qPDMCtdbt34DMz+YS49jj9rW1/3HnZnyxjusXLUagDVr17FseWlWx+1xTHcmTnoNgFffeJufdPkhZsbyFV/yzebN2/b3wdwF7P+Dtjt7erGQrEILWWWZc0ugD/DduV4G/Gu3jCgmCgpa8ugjfyI3N4ecnByeeeYFXor+55La64M583nh5al0OHD/baWHqwZfREn0BfvtNLapb/6Ln3b7Efvsvde2bQ9svx+/+sVAiq6+nqQnyc/L4/pf/xetW1We55zZrw9Dh9/FyedeQqOGDbjrlusA+HTxEu564CHMDHfn5+edycEHtq/u065VEjG5KGqZZgyY2SPAY+7+TjnLnnD3SounKmtIeTYte7umhyABym92gO3qPs7fb0DWMeeJzyfs8vF2l4yZs7sPyrBMV7VEJDhxqTnrJhQRiZXQa8nZUnAWkVjR7dsiIgFSWUNEJEBxma2h4CwisaKyhohIgHRBUEQkQKo5i4gEKC5lDT0yVERixd2zbpUxs8VmNtfMZpvZzKiviZlNMbOPo7+N09YfamaLzGyhmfXZlfNQcBaRWEngWbcs9XD3zu7+4+j9dcBUd+8ATI3eY2adgELgUKAv8KCZ5e7seSg4i0isJPGs207qD4yJXo8BzkjrH+fum939M2AR0G1nD6LgLCKxUpWyhpkVmdnMtFb03d0Br5rZv9OWtXT3kuhYJUCLqL8NsCRt2+Kob6fogqCIxEpVMuL0HwapwNHuvszMWgBTzOyjDOuW94S7nU7PlTmLSKxU528Iuvuy6O8KYAKpMkWpmRUARH9XRKsXA+3SNm8LLNvZ81BwFpFYSbhn3TIxs3pm1uDb18BJwDzgeeCiaLWLgInR6+eBQjOra2btgQ7AjJ09D5U1RCRWqnGec0tgQvRDunnAE+7+spm9D4w3s0HAF8A5AO4+38zGAwuAMuByd0/s7MEVnEUkVqorOLv7p8APy+lfCfSsYJsRwIjqOL6Cs4jESjY3l9QGCs4iEitxuX1bwVlEYkUPPhIRCVDC4/HQUAVnEYkV1ZxFRAKkmrOISIBUcxYRCVBSZQ0RkfAocxYRCZBma4iIBEhlDRGRAKmsISISIGXOIiIBUuYsIhKgxM4/QjkoCs4iEiu6fVtEJEC6fVtEJEDKnEVEAqTZGiIiAdJsDRGRAOn2bRGRAKnmLCISINWcRUQCpMxZRCRAmucsIhIgZc4iIgHSbA0RkQDpgqCISIBU1hARCZDuEBQRCZAyZxGRAMWl5mxx+ZapDcysyN1H1fQ4JCz6XEh5cmp6AN8zRTU9AAmSPheyAwVnEZEAKTiLiARIwXnPUl1RyqPPhexAFwRFRAKkzFlEJEAKziIiAVJw3kPMrK+ZLTSzRWZ2XU2PR2qemT1qZivMbF5Nj0XCo+C8B5hZLvAX4GSgE3CemXWq2VFJAEYDfWt6EBImBec9oxuwyN0/dfctwDigfw2PSWqYu78FfF3T45AwKTjvGW2AJWnvi6M+EZFyKTjvGVZOn+YwikiFFJz3jGKgXdr7tsCyGhqLiNQCCs57xvtABzNrb2Z1gELg+Roek4gETMF5D3D3MuAK4BXgQ2C8u8+v2VFJTTOzJ4F3gY5mVmxmg2p6TBIO3b4tIhIgZc4iIgFScBYRCZCCs4hIgBScRUQCpOAsIhIgBWcRkQApOIuIBOh/AfPyznM5slBaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the Confusion Matrix\n",
    "conf = confusion_matrix(y_valid, y_pred)\n",
    "sns.heatmap(conf, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save(\"Models/malaria.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
